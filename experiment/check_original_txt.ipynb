{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original.txtの中身を調べる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* すでに表記ゆれはある程度前処理されている\n",
    "* original.txtからデータセットを作成する方法はいくつかある\n",
    "* capoの方は、半音下げ(-1) ~ capo5(-5)までが大半を占めているので、6と7は削除でよさそう\n",
    "* chordの方はいろいろある。低頻度のコードを削除する、何らかのコードで置き換えるなど\n",
    "* とりあえず削除する方向で"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "orignal_path=Path(\"../data/original.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_list(original_path):\n",
    "    with orignal_path.open(\"r\") as f:\n",
    "        songs = f.readlines()\n",
    "    result=[]\n",
    "    for song in songs:\n",
    "        song=song.rstrip('\\n')\n",
    "        divided=song.split(\" \")\n",
    "        song_dic={\"chords\":divided[:-1],\"rec_capo\":divided[-1]}\n",
    "        result.append(song_dic)\n",
    "    return result\n",
    "\n",
    "def remove_rare_capo_song(songs):\n",
    "    \"\"\"-6,-7はほとんどないので除去する.\"\"\"\n",
    "    removed=[]\n",
    "    for song in songs:\n",
    "        if song[\"rec_capo\"] not in ['-6','-7']:\n",
    "            removed.append(song)\n",
    "    return removed\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(songs,val_rate, test_rate,seed=None):\n",
    "    songs_train_val,songs_test= train_test_split(songs,test_size=test_rate,random_state=seed)\n",
    "    songs_train,songs_val= train_test_split(songs,test_size=val_rate,random_state=seed)\n",
    "    return songs_train,songs_val,songs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def retrieve_chord_stat(songs):\n",
    "    chord_dict = Counter()\n",
    "    for song in songs:\n",
    "        for chord in song[\"chords\"]: \n",
    "            chord_dict[chord]+=1\n",
    "    return chord_dict\n",
    "\n",
    "def retrieve_capo_stat(songs):\n",
    "    capo_dict =  Counter()\n",
    "    for song in songs:\n",
    "        capo_dict[song[\"rec_capo\"]]+=1\n",
    "    return capo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs=get_song_list(orignal_path)\n",
    "songs=remove_rare_capo_song(songs)\n",
    "songs_train,songs_valid,songs_test=split_dataset(songs,0.1,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_stat=retrieve_chord_stat(songs_train)\n",
    "capo_stat=retrieve_capo_stat(songs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chordの出現頻度調査\n",
    "* 低頻度chordはparseミスとかも含むので除去したい\n",
    "* 5回以下しか出現しない約140個のコードを対象？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chords :847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hikaru_ogura/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Total chords :{len(chord_stat.keys())}\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "edges = range(0,100,5)\n",
    "ax.hist(list(chord_stat.values()), bins=edges)\n",
    "ax.set_title('histogram of chord')\n",
    "ax.set_xlabel('frequency')\n",
    "ax.set_ylabel('the number of chords')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_rare_chord(chords_list,onehot_dict,token):\n",
    "    result=[]\n",
    "    for chords in chords_list:\n",
    "        result_inner=[]\n",
    "        for i,chord in enumerate(chords):\n",
    "            if chord not in onehot_dict.keys():\n",
    "                result_inner.append(token)\n",
    "            else:\n",
    "                result_inner.append(chord)\n",
    "        result.append(result_inner)\n",
    "    return result\n",
    "\n",
    "def get_onehot_dict(chord_stat,threshold,token):\n",
    "    onehot_dict={}\n",
    "    i=0\n",
    "    for chord,freq in chord_stat.items():\n",
    "        if freq>threshold:\n",
    "            onehot_dict[chord]=i\n",
    "            i+=1\n",
    "    onehot_dict[token]=i\n",
    "    return onehot_dict  \n",
    "\n",
    "def count_and_normalize_chord_features(tokenized,onehot_dict):\n",
    "    X=[]\n",
    "    features_num=len(onehot_dict)\n",
    "    for chords in tokenized:\n",
    "        x=[0]*features_num\n",
    "        for chord in chords:\n",
    "            x[onehot_dict[chord]]+=1\n",
    "        x=np.array(x)\n",
    "        X.append(x/sum(x))\n",
    "    return np.array(X)\n",
    "\n",
    "def get_chord_features(songs,onehot_dict=None,threshold=5,token=\"<UNK>\"):\n",
    "    \"\"\"train : onehot_dictがNone. valid or test : onehot_dictを与える.\"\"\"\n",
    "    chords_list=[song[\"chords\"] for song in songs]\n",
    "    if onehot_dict is None:\n",
    "        chord_stat=retrieve_chord_stat(songs)\n",
    "        onehot_dict=get_onehot_dict(chord_stat,threshold,token)\n",
    "    tokenized=tokenize_rare_chord(chords_list,onehot_dict,token)\n",
    "    X=count_and_normalize_chord_features(tokenized,onehot_dict)\n",
    "    return X, onehot_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_features_train, onehot_dict=get_chord_features(songs_train)\n",
    "chord_features_valid, _ =get_chord_features(songs_valid,onehot_dict)\n",
    "chord_features_test, _ =get_chord_features(songs_test,onehot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35995, 684), (4000, 684), (7999, 684))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chord_features_train.shape,chord_features_valid.shape,chord_features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_chord_features_train=chord_features_train.repeat(7,axis=0)\n",
    "expanded_chord_features_valid = chord_features_valid.repeat(7,axis=0)\n",
    "expanded_chord_features_test = chord_features_test.repeat(7,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_capos(n,dupulication_capo_order=np.array(['1','0','-1','-2','-3','-4','-5'])):\n",
    "    \"\"\"n回dupulication_capo_orderを繰り返す.\"\"\"\n",
    "    return np.tile(dupulication_capo_order,n)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def capo_onehot_encode(capo):\n",
    "    \"\"\"文字列のcapoをonehot encoding\"\"\"\n",
    "    binarizer=LabelBinarizer()\n",
    "    binarized=binarizer.fit_transform(capo)\n",
    "    return binarized, binarizer\n",
    "\n",
    "def create_compares(songs,dupulication_capo_order=np.array(['1','0','-1','-2','-3','-4','-5'])):\n",
    "    compares=[]\n",
    "    for i, song in enumerate(songs_train):\n",
    "        rec=song[\"rec_capo\"]\n",
    "        pos_j=int(np.where(dupulication_capo_order==rec)[0])\n",
    "        for j in range(7):\n",
    "            if j != pos_j:\n",
    "                compares.append([7*i + pos_j, 7*i + j])\n",
    "    return np.array(compares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "compares=create_compares(songs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_capos_train=duplicate_capos(len(songs_train))\n",
    "duplicated_capos_valid = duplicate_capos(len(songs_valid))\n",
    "duplicated_capos_test = duplicate_capos(len(songs_test))\n",
    "capo_features_train,capo_encoder = capo_onehot_encode(duplicated_capos_train)\n",
    "capo_features_valid = capo_encoder.transform(duplicated_capos_valid)\n",
    "capo_features_test = capo_encoder.transform(duplicated_capos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.concatenate([expanded_chord_features_train, capo_features_train], 1)\n",
    "X_valid = np.concatenate([expanded_chord_features_valid, capo_features_valid], 1)\n",
    "X_test = np.concatenate([expanded_chord_features_test, capo_features_test], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251965, 691), (28000, 691), (55993, 691))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "X_train_sp=sparse.csr_matrix(X_train)\n",
    "X_valid_sp=sparse.csr_matrix(X_valid)\n",
    "X_test_sp=sparse.csr_matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FMRecommender(init_stdev=0.1, l2_reg=None, l2_reg_V=0.1, l2_reg_w=0.1,\n",
       "       n_iter=455, random_state=123, rank=8, step_size=0.1)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastFM import bpr\n",
    "model=bpr.FMRecommender(n_iter=455)\n",
    "model.fit(X_train_sp,compares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ranking(X,model):\n",
    "    pred=model.predict(X)\n",
    "    reshaped=np.reshape(pred,(-1,7))\n",
    "    results=[]\n",
    "    for i in range(len(reshaped)):\n",
    "        results.append(return_sorted_capo(reshaped[i]))\n",
    "    return results\n",
    "\n",
    "def return_sorted_capo(pred,dupulication_capo_order=np.array(['1','0','-1','-2','-3','-4','-5'])):\n",
    "    index = [0]*7\n",
    "    for j, rank in enumerate(np.argsort(pred[::-1])):\n",
    "        index[rank] = j\n",
    "    return dupulication_capo_order[index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2'),\n",
       " array(['0', '-1', '-2', '-3', '-4', '-5', '1'], dtype='<U2')]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking=predict_ranking(X_train_sp,model)\n",
    "ranking[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=model.V_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
