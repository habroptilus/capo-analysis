{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastFMのclassifierを使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "from tools.preprocess.common import CommonPreprocessor\n",
    "from tools.preprocess.frequency_vectorizer import FrequencyVectorizer\n",
    "from tools.model.fm_bpr import FMBPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orignal_path=Path(\"../data/original.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp=CommonPreprocessor(rare_capo_list=['-6', '-7'],val_rate=0.1,test_rate=0.2,split_seed=0)\n",
    "songs=cp.get_song_list(orignal_path)\n",
    "songs=cp.remove_rare_capo_song(songs)\n",
    "songs_train, songs_valid, songs_test=cp.split_dataset(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_stat=cp.retrieve_chord_stat(songs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_list_train = [song[\"chords\"] for song in songs_train]\n",
    "chords_list_valid = [song[\"chords\"] for song in songs_valid]\n",
    "chords_list_test = [song[\"chords\"] for song in songs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv=FrequencyVectorizer(chord_stat, threshold=5, token=\"<UNK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=fv.get_chord_features(chords_list_train)\n",
    "X_valid =fv.get_chord_features(chords_list_valid)\n",
    "X_test=fv.get_chord_features(chords_list_test)\n",
    "y_train=[song[\"rec_capo\"] for song in songs_train]\n",
    "y_valid=[song[\"rec_capo\"] for song in songs_valid]\n",
    "y_test=[song[\"rec_capo\"] for song in songs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from fastFM import als\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from numpy.random import randint\n",
    "\n",
    "\n",
    "class FMClassifier:\n",
    "    def __init__(self, n_iter, rank,dupulication_capo_order):\n",
    "        self.model = als.FMClassification(n_iter=n_iter, rank=rank)\n",
    "        self.dupulication_capo_order = dupulication_capo_order\n",
    "        self.capo_encoder = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: np.arrayでchord featureのみ。複製前.\n",
    "        :param y: recomennded capo. 文字列. len(X)=len(y)\n",
    "        \"\"\"\n",
    "        print(\"Preprocessing features...\")\n",
    "        X_dup = self.duplicate_add_capo_features(X)\n",
    "        print(\"Creating labels...\")\n",
    "        labels = self.create_labels(y)\n",
    "        print(\"Sampling labels...\")\n",
    "        X_sampled, y_sampled= self.sample_dataset(X_dup,labels)\n",
    "        print(\"sparse\")\n",
    "        X_sp = sparse.csr_matrix(X_sampled)\n",
    "        print(\"Start training...\")\n",
    "        return self.model.fit(X_sp, y_sampled)\n",
    "                       \n",
    "    def sample_dataset(self,X_dup,labels):\n",
    "        X_dup_pos=X_dup[labels==1]\n",
    "        X_dup_neg=X_dup[labels==-1]\n",
    "        diff=randint(0,len(self.dupulication_capo_order)-1,len(X_dup_neg)//(len(self.dupulication_capo_order)-1))\n",
    "        sampled_index=np.array([(len(self.dupulication_capo_order)-1)*i for i in range(len(X_dup_neg)//(len(self.dupulication_capo_order)-1))])+diff\n",
    "        print(\"sampling\")\n",
    "        X_dup_neg_sampled=X_dup_neg[sampled_index]\n",
    "        assert len(X_dup_neg_sampled)==len(X_dup_pos)\n",
    "        print(\"concat\")\n",
    "        X_sampled = np.concatenate([X_dup_pos, X_dup_neg_sampled])\n",
    "        y_sampled=np.concatenate([np.ones(len(X_dup_pos)),-np.ones(len(X_dup_neg_sampled))])\n",
    "        assert len(X_sampled)==len(y_sampled)\n",
    "        print(X_sampled.shape,y_sampled.shape)\n",
    "        print(\"shuffle\")\n",
    "        return self.shuffle_samples(X_sampled,y_sampled)\n",
    "    \n",
    "    def shuffle_samples(self,X, y):\n",
    "        zipped = list(zip(X, y))\n",
    "        np.random.shuffle(zipped)\n",
    "        X_result, y_result = zip(*zipped)\n",
    "        return np.asarray(X_result), np.asarray(y_result)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        :param X: np.arrayでchord featureのみ。複製前.\n",
    "        :param y: recomennded capo. 文字列. len(X)=len(y)\n",
    "         :return e.g. np.array([[\"+1\", \"-4\", \"0\",...],[\"-1\", \"-3\", \"+1\",...],...])\n",
    "        \"\"\"\n",
    "        rankings = self.predict_ranking(X)\n",
    "        return np.array([ranking[0] for ranking in rankings])\n",
    "\n",
    "    def predict_ranking(self, X):\n",
    "        \"\"\"入力した曲に対しておすすめcapoのランキングを返す.\n",
    "\n",
    "         :param X: np.arrayでchord featureのみ。複製前.\n",
    "         :return e.g. np.array([\"+1\", \"-4\", \"0\",...])\n",
    "        \"\"\"\n",
    "        X_dup = self.duplicate_add_capo_features(X)\n",
    "        X_sp = sparse.csr_matrix(X_dup)\n",
    "        pred = self.model.predict(X_sp)\n",
    "        reshaped = np.reshape(pred, (-1, len(self.dupulication_capo_order)))\n",
    "        results = []\n",
    "        for i in range(len(reshaped)):\n",
    "            results.append(self.return_sorted_capo(reshaped[i]))\n",
    "        return results\n",
    "\n",
    "    def get_all_embeddings(self):\n",
    "        \"\"\"embeddingを全てまとめて取得\"\"\"\n",
    "        return self.model.V_.T\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        \"\"\"学習結果としてchordとcapoのembeddingを取得\"\"\"\n",
    "        embeddings = self.get_all_embeddings()\n",
    "        chord_embeddings = embeddings[:-len(self.dupulication_capo_order), :]\n",
    "        capo_embeddings = embeddings[-len(self.dupulication_capo_order):, :]\n",
    "        return chord_embeddings, capo_embeddings\n",
    "\n",
    "    def create_labels(self, y):\n",
    "        \"\"\"おすすめcapo=yを用いてlabelsを作成.\"\"\"\n",
    "        labels = []\n",
    "        for rec in y:\n",
    "            pos_j = int(np.where(self.dupulication_capo_order == rec)[0])\n",
    "            for j in range(len(self.dupulication_capo_order)):\n",
    "                if j != pos_j:\n",
    "                    labels.append(-1)\n",
    "                else:\n",
    "                    labels.append(1)\n",
    "        return np.array(labels)\n",
    "\n",
    "    def return_sorted_capo(self, pred):\n",
    "        \"\"\"予測したscoreを元にrankingになるようにsortする.\"\"\"\n",
    "        index = [0] * len(self.dupulication_capo_order)\n",
    "        for j, rank in enumerate(np.argsort(pred[::-1])):\n",
    "            index[rank] = j\n",
    "        return self.dupulication_capo_order[index]\n",
    "\n",
    "    def evaluate_top1(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: np.arrayでchord featureのみ。複製前.\n",
    "        :param y: recomennded capo. 文字列. len(X)=len(y)\n",
    "        \"\"\"\n",
    "        pred = self.predict(X)\n",
    "        return accuracy_score(y, pred)\n",
    "\n",
    "    def capo_onehot_encode(self, duplicated_capos):\n",
    "        \"\"\"文字列のcapoをonehot encoding\"\"\"\n",
    "        if self.capo_encoder is None:\n",
    "            self.capo_encoder = LabelBinarizer()\n",
    "            return self.capo_encoder.fit_transform(duplicated_capos)\n",
    "        else:\n",
    "            return self.capo_encoder.transform(duplicated_capos)\n",
    "\n",
    "    def duplicate_capos(self, n):\n",
    "        \"\"\"n回dupulication_capo_orderを繰り返す.\"\"\"\n",
    "        return np.tile(self.dupulication_capo_order, n)\n",
    "\n",
    "    def duplicate_add_capo_features(self, X):\n",
    "        \"\"\"\n",
    "        :param X: np.arrayでchord featureのみ。複製前.\n",
    "        \"\"\"\n",
    "        expanded_chord_features = X.repeat(len(self.dupulication_capo_order), axis=0)\n",
    "        duplicated_capos = self.duplicate_capos(len(X))\n",
    "        capo_features = self.capo_onehot_encode(duplicated_capos)\n",
    "        return np.concatenate([expanded_chord_features, capo_features], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=FMClassifier(n_iter=10000, rank=10, dupulication_capo_order=np.array(['1','0','-1','-2','-3','-4','-5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing features...\n",
      "Creating labels...\n",
      "Sampling labels...\n",
      "sampling\n",
      "concat\n",
      "(71990, 698) (71990,)\n",
      "shuffle\n",
      "sparse\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings=model.predict_ranking(X_valid)\n",
    "rankings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_top1= model.predict(X_valid)\n",
    "pred_top1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_top1(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_embeddings, capo_embeddings=model.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_embeddings.shape,capo_embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
